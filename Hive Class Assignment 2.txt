Scenario Based questions:
1) Will the reducer work or not if you use “Limit 1” in any HiveQL query?

- in a simple select query it does not use reducer

- in query which contains GROUP BY etc it will use reducer 

- hive.fetch.task.conversion property of Hive lowers the latency of MapReduce overhead

2) Suppose I have installed Apache Hive on top of my Hadoop cluster using default metastore 
configuration. Then, what will happen if we have multiple clients trying to access Hive at 
the same time?

- It should display an error. To enable multiple client access, it should be a standalone 
and not default



3) Suppose, I create a table that contains details of all the transactions done by the 
customers: CREATE TABLE transaction_details (cust_id INT, amount FLOAT, month STRING, 
country STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ‘,’ ;
Now, after inserting 50,000 records in this table, I want to know the total revenue 
generated for each month. But, Hive is taking too much time in processing this query. 
How will you solve this problem and list the steps that I will be taking in order to 
do so?

- Enable dynamic partition modes as below: 
SET hive.exec.dynamic.partition = true;
SET hive.exec.dynamic.partition.mode = nonstrict;

- the table is already created and data has been loaded will do the below steps 
will create a schema for table partition 
CREATE TABLE partitioned_transaction 
(
cust_id INT, 
amount FLOAT, 
country STRING) 
PARTITIONED BY (month STRING) 
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ‘,’ ; 


- load data 

INSERT OVERWRITE TABLE partitioned_transaction 
PARTITION (month) SELECT cust_id, amount, country, month 
FROM transaction_details;


4) How can you add a new partition for the month December in the above partitioned table?

- insert command 
- dynamic partions non strict do not do alter 
- alter can be used if the partition was in strict mode 

5) I am inserting data into a table based on partitions dynamically. But, I received an 
error – FAILED ERROR IN SEMANTIC ANALYSIS: Dynamic partition strict mode requires at least 
one static partition column. How will you remove this error?

- by using 
SET hive.exec.dynamic.partition.mode = nonstrict;

- or run the partition in static by giving on static partition.


6) Suppose, I have a CSV file – ‘sample.csv’ present in ‘/temp’ directory with the 
following entries:
id first_name last_name email gender ip_address
How will you consume this CSV file into the Hive warehouse using built-in SerDe?

- org.apache.hadoop.hive.serde2.OpenCSVSerde



7) Suppose, I have a lot of small CSV files present in the input directory in HDFS and 
I want to create a single Hive table corresponding to these files. The data in these 
files are in the format: {id, name, e-mail, country}. Now, as we know, Hadoop performance
degrades when we use lots of small files.
So, how will you solve this problem where we want to create a single Hive table for lots 
of small files without degrading the performance of the system?

- using SequenceFile 

8) 
LOAD DATA LOCAL INPATH ‘Home/country/state/’
OVERWRITE INTO TABLE address;

The following statement failed to execute. What can be the cause?


- load data local inpath 'file:///Home/country/state/'
- insert overwrite table address

9) Is it possible to add 100 nodes when we already have 100 nodes in Hive? If yes, how?

- yes 
- By adding new DataNode IP address, hostname & necessary details in /etc/hosts slaves file



10 
Hive Join operations

Create a  table named CUSTOMERS(ID | NAME | AGE | ADDRESS   | SALARY)
Create a Second  table ORDER(OID | DATE | CUSTOMER_ID | AMOUNT
)

Now perform different joins operations on top of these tables
(Inner JOIN, LEFT OUTER JOIN ,RIGHT OUTER JOIN ,FULL OUTER JOIN)


Assuming ID and Customer_ID are primary keys or close to unique identifier columns 

- Inner join 
SELECT c. ID, c.NAME, c.SALARY, o.OID, o.DATE, o.AMOUNT 
FORM CUSTOMER c
INNER JOIN ORDER o
ON c.IC = o.CUSTOMER_ID
ORDER BY c.ID;

- Left outer join 
SELECT c. ID, c.NAME, c.SALARY, o.OID, o.DATE, o.AMOUNT 
FORM CUSTOMER c
LEFT JOIN ORDER o
ON c.IC = o.CUSTOMER_ID
ORDER BY c.ID;

- right outer join 
SELECT c. ID, c.NAME, c.SALARY, o.OID, o.DATE, o.AMOUNT 
FORM CUSTOMER c
RIGHT JOIN ORDER o
ON c.IC = o.CUSTOMER_ID
ORDER BY c.ID;

- full outer join 
SELECT c. ID, c.NAME, c.SALARY, o.OID, o.DATE, o.AMOUNT 
FORM CUSTOMER c
FULL OUTER JOIN ORDER o
ON c.IC = o.CUSTOMER_ID
ORDER BY c.ID;


BUILD A DATA PIPELINE WITH HIVE

Download a data from the given location - 
https://archive.ics.uci.edu/ml/machine-learning-databases/00360/

1. Create a hive table as per given schema in your dataset 
-
CREATE DATABASE assign2;
USE assign2;

CREATE TABLE airquality
(
DATE date,
TIME timestamp,
CO_GT float,
PT08_S1_CO FLOAT,
NMHC_GT FLOAT,
C6H6_GT FLOAT,	
PT08_S2_NMHC FLOAT,	
NOx_GT FLOAT,	
PT08_S3_NOx FLOAT,	
NO2_GT FLOAT,	
PT08_S4_NO2 FLOAT,
PT08_S5_O3 FLOAT,
T FLOAT,
RH FLOAT,	
AH FLOAT
)
row format delimited
fields terminated by ','
tblproperties("skip.header.line.count"="1");


set hive.cli.print.header = true;



select from_unixtime(unix_timestamp('03/10/2015' ,'MM/dd/yyyy'), 'yyyy-MM-dd') from airquality;




2. try to place a data into table location
-
hadoop fs -put AirQualityUCI1.csv /input_data
load data inpath '/input_data/AirQualityUCI1.csv' into table airquality;



3. Perform a select operation.
-
select * from airquality limit 10;

 
4. Fetch the result of the select operation in your local as a csv file . 
-
vi fetchdata.hql

the above file will have --> SELECT * FROM airquality;

hive -f fetchdata.hql >> fetchdata1.csv

view fetchdata1.csv




5. Perform group by operation . 
- 
SELECT DATE, TIME, CO_GT
FROM airquality
GROUP BY DATE;


7. Perform filter operation at least 5 kinds of filter examples . 
- 
SELECT DATE, TIME, AVG(CO_GT), AVG(C6H6_GT)
FROM airquality
WHERE TIME LIKE '^([0-1]?[0-9]|2[0-3]):[0-5][0-9]$'
AND C6H6_GT = 1.1 
GROUP BY DATE
ORDER BY AVG(CO_GT) DESC;




8. show and example of regex operation
-
SELECT DATE, TIME, CO_GT
FROM airquality
WHERE TIME LIKE '^([0-1]?[0-9]|2[0-3]):[0-5][0-9]$';



9. alter table operation 
- 
ALTER TABLE employee airquality to airquality1


10. drop table operation
- 
drop table airquality;



12. order by operation. 
-
SELECT DATE, TIME, CO_GT
FROM airquality1
ORDER BY CO_GT ASC;


13. where clause operations you have to perform . 
- 
SELECT DATE, TIME, CO_GT
FROM airquality1
WHERE CO_GT = 1;



14. sorting operation you have to perform. 

SELECT DATE, TIME, CO_GT
FROM airquality1
SORT BY CO_GT ASC;


15. distinct operation you have to perform. 
-
SELECT DATE, TIME, DISTINCT(CO_GT)
FROM airquality1;


16. like an operation you have to perform. 
-
SELECT DATE, TIME, CO_GT
FROM airquality1
WHERE TIME LIKE '^([0-1]?[0-9]|2[0-3]):[0-5][0-9]$';


17. union operation you have to perform. 
-
SELECT CO_GT 
FROM airquality1
UNION
SELECT CO_GT 
FROM viewairquality1
ORDER BY CO_GT;



18. table view operation you have to perform.

CREATE VIEW viewairquality1 AS
SELECT DATE, TIME, DISTINCT(CO_GT)
FROM airquality1;
